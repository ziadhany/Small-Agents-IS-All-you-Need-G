{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install langchain-huggingface langchain_community pinecone langchain-pinecone sentence-transformers pytube whisper gpt4all transformers accelerate bitsandbytes>0.37.0 git+https://github.com/openai/whisper.git langgraph tavily-python -q --upgrade transformers","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:46:03.521095Z","iopub.status.idle":"2024-10-04T11:46:03.521500Z","shell.execute_reply.started":"2024-10-04T11:46:03.521297Z","shell.execute_reply":"2024-10-04T11:46:03.521317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nHUGGINGFACE_TOKEN=\"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\"\nTAVILY_API_KEY=\"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\"\nPINECONE_API_KEY=\"28298672-b55a-4abf-b424-06ff620c82cf\"\n\nos.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\nos.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\nos.environ[\"HUGGINGFACE_TOKEN\"] = HUGGINGFACE_TOKEN","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:46:03.522510Z","iopub.status.idle":"2024-10-04T11:46:03.522901Z","shell.execute_reply.started":"2024-10-04T11:46:03.522716Z","shell.execute_reply":"2024-10-04T11:46:03.522739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nimport os\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nlogin(token=HUGGINGFACE_TOKEN)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:46:06.963050Z","iopub.execute_input":"2024-10-04T11:46:06.963494Z","iopub.status.idle":"2024-10-04T11:46:07.111704Z","shell.execute_reply.started":"2024-10-04T11:46:06.963452Z","shell.execute_reply":"2024-10-04T11:46:07.110753Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"# For Pinecone initialization\nfrom pinecone import Pinecone\npc = Pinecone(api_key=PINECONE_API_KEY)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:46:10.388993Z","iopub.execute_input":"2024-10-04T11:46:10.389708Z","iopub.status.idle":"2024-10-04T11:46:10.395851Z","shell.execute_reply.started":"2024-10-04T11:46:10.389664Z","shell.execute_reply":"2024-10-04T11:46:10.394929Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"######## if you want to delete the transcribition and use another youtube URL or video \n#import os\n#Stanford CS229 I Machine Learning I Building Large Language Models (LLMs)\nYOUTUBE_VIDEO = \"https://youtu.be/9vM4p9NN0Ts?si=cnSBOcBTp0Uh6W6Q\"\n#file_to_delete = 'trans.txt'\n#if os.path.exists(file_to_delete):\n    #os.remove(file_to_delete)\n    #print(f\"{file_to_delete} has been deleted.\")\n#else:\n    #print(f\"{file_to_delete} does not exist.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:46:11.910905Z","iopub.execute_input":"2024-10-04T11:46:11.911686Z","iopub.status.idle":"2024-10-04T11:46:11.915992Z","shell.execute_reply.started":"2024-10-04T11:46:11.911642Z","shell.execute_reply":"2024-10-04T11:46:11.914954Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from langchain_community.chat_models import ChatOllama\nfrom langchain_core.output_parsers import JsonOutputParser\nimport os\nfrom pytube.innertube import _default_clients\nfrom pytube import cipher\nfrom langchain_community.retrievers import TavilySearchAPIRetriever\nimport re\nimport whisper\nfrom pytube import YouTube\nimport os\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nimport torch\nimport tempfile\nimport warnings\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_community.embeddings import GPT4AllEmbeddings\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import DocArrayInMemorySearch\nfrom sentence_transformers import SentenceTransformer\nfrom tqdm.autonotebook import tqdm\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\nimport time\nfrom langchain.docstore.document import Document\nimport json\nfrom langchain.vectorstores import Pinecone\nfrom pinecone import Pinecone, ServerlessSpec\nfrom langchain_pinecone import PineconeVectorStore\nfrom typing_extensions import TypedDict\nfrom typing import List\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms import BaseLLM\nfrom langgraph.graph import END, StateGraph ,START\nimport requests\nimport urllib.parse\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:46:12.969041Z","iopub.execute_input":"2024-10-04T11:46:12.969481Z","iopub.status.idle":"2024-10-04T11:46:12.979994Z","shell.execute_reply.started":"2024-10-04T11:46:12.969438Z","shell.execute_reply":"2024-10-04T11:46:12.979105Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"_default_clients[\"ANDROID\"][\"context\"][\"client\"][\"clientVersion\"] = \"19.08.35\"\n_default_clients[\"IOS\"][\"context\"][\"client\"][\"clientVersion\"] = \"19.08.35\"\n_default_clients[\"ANDROID_EMBED\"][\"context\"][\"client\"][\"clientVersion\"] = \"19.08.35\"\n_default_clients[\"IOS_EMBED\"][\"context\"][\"client\"][\"clientVersion\"] = \"19.08.35\"\n_default_clients[\"IOS_MUSIC\"][\"context\"][\"client\"][\"clientVersion\"] = \"6.41\"\n_default_clients[\"ANDROID_MUSIC\"] = _default_clients[\"ANDROID_CREATOR\"]\n\n\n\ndef get_throttling_function_name(js: str) -> str:\n    \"\"\"Extract the name of the function that computes the throttling parameter.\n\n    :param str js:\n        The contents of the base.js asset file.\n    :rtype: str\n    :returns:\n        The name of the function used to compute the throttling parameter.\n    \"\"\"\n    function_patterns = [\n        r'a\\.[a-zA-Z]\\s*&&\\s*\\([a-z]\\s*=\\s*a\\.get\\(\"n\"\\)\\)\\s*&&\\s*'\n        r'\\([a-z]\\s*=\\s*([a-zA-Z0-9$]+)(\\[\\d+\\])?\\([a-z]\\)',\n        r'\\([a-z]\\s*=\\s*([a-zA-Z0-9$]+)(\\[\\d+\\])\\([a-z]\\)',\n    ]\n    #logger.debug('Finding throttling function name')\n    for pattern in function_patterns:\n        regex = re.compile(pattern)\n        function_match = regex.search(js)\n        if function_match:\n            #logger.debug(\"finished regex search, matched: %s\", pattern)\n            if len(function_match.groups()) == 1:\n                return function_match.group(1)\n            idx = function_match.group(2)\n            if idx:\n                idx = idx.strip(\"[]\")\n                array = re.search(\n                    r'var {nfunc}\\s*=\\s*(\\[.+?\\]);'.format(\n                        nfunc=re.escape(function_match.group(1))),\n                    js\n                )\n                if array:\n                    array = array.group(1).strip(\"[]\").split(\",\")\n                    array = [x.strip() for x in array]\n                    return array[int(idx)]\n\n    raise RegexMatchError(\n        caller=\"get_throttling_function_name\", pattern=\"multiple\"\n    )\n\ncipher.get_throttling_function_name = get_throttling_function_name\n\nmodel_nameGraphState = \"all-MiniLM-L6-v2.gguf2.f16.gguf\"\ngpt4all_kwargs = {'allow_download': 'True'}\nembeddings = GPT4AllEmbeddings(\n    model_name=\"all-MiniLM-L6-v2.gguf2.f16.gguf\",\n    gpt4all_kwargs=gpt4all_kwargs\n)\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\n\nif not os.path.exists(\"trans.txt\"):\n    youtube = YouTube(YOUTUBE_VIDEO)\n    audio = youtube.streams.filter(only_audio=True).first()\n\n    \n    whisper_model = whisper.load_model(\"base\").to(device)\n\n    with tempfile.TemporaryDirectory() as tmpdir:\n        file = audio.download(output_path=tmpdir)\n        \n        trans = whisper_model.transcribe(file, fp16=torch.cuda.is_available())[\"text\"].strip()\n\n        with open(\"trans.txt\", \"w\") as file:\n            file.write(trans)\n\nprint(\"Transcription completed successfully.\")\n\n\nloader = TextLoader(\"trans.txt\")\ntext_documents = loader.load()\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\ndocuments = text_splitter.split_documents(text_documents)\npc = Pinecone(api_key=PINECONE_API_KEY)\n\nindex_name = \"meta\"\nexisting_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n\nif index_name not in existing_indexes:\n    pc.create_index(\n        name=index_name,\n        dimension=384,\n        metric=\"cosine\",\n        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n    )\n    while not pc.describe_index(index_name).status[\"ready\"]:\n        time.sleep(1)\n\n\npinecone_vector_store = PineconeVectorStore.from_documents(\n    documents=documents,\n    embedding=embeddings,\n    index_name=index_name\n    \n)\nretriever=pinecone_vector_store.as_retriever()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:46:14.140401Z","iopub.execute_input":"2024-10-04T11:46:14.141060Z","iopub.status.idle":"2024-10-04T11:50:59.206967Z","shell.execute_reply.started":"2024-10-04T11:46:14.141016Z","shell.execute_reply":"2024-10-04T11:50:59.206123Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 78.2MiB/s]\n","output_type":"stream"},{"name":"stdout","text":"Transcription completed successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain import PromptTemplate, LLMChain\n\nmodel_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n#tokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=True\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:50:59.208989Z","iopub.execute_input":"2024-10-04T11:50:59.209415Z","iopub.status.idle":"2024-10-04T11:52:35.615106Z","shell.execute_reply.started":"2024-10-04T11:50:59.209369Z","shell.execute_reply":"2024-10-04T11:52:35.614374Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7e145476ca740d394f1a27b83a6d7a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db20a4a7774d4c50ae3f9d5ee6ebd6e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e7e8a842409451390f8bfea07427958"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6479f74be6f447889065c24c79a8bc21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10abc0938463415590fc4673b7e6eeb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e2536d6b5a0489a80e9467d0f11785b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bac95d1ad5414eb38892958b7875a81e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29c7e1be7b68468d8afe0aba5a030ff3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b323bbf648454264b542f9bddc5e1bdb"}},"metadata":{}}]},{"cell_type":"code","source":"#import torch\n#from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n\n#quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n\n#model = AutoModelForCausalLM.from_pretrained(\n#    \"meta-llama/Llama-3.1-8B-Instruct\", \n#    quantization_config=quantization_config, \n#    torch_dtype=torch.bfloat16\n    \n#)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:52:35.616300Z","iopub.execute_input":"2024-10-04T11:52:35.616607Z","iopub.status.idle":"2024-10-04T11:52:35.622923Z","shell.execute_reply.started":"2024-10-04T11:52:35.616574Z","shell.execute_reply":"2024-10-04T11:52:35.622067Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig , pipeline\nfrom langchain.llms.huggingface_pipeline import HuggingFacePipeline\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")\npipe = pipeline(\n    \"text-generation\",\n    return_full_text= False ,\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=512, \n    temperature=0.1 \n \n)\n\n\nllm = HuggingFacePipeline(pipeline=pipe)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:52:35.625464Z","iopub.execute_input":"2024-10-04T11:52:35.626254Z","iopub.status.idle":"2024-10-04T11:52:44.570802Z","shell.execute_reply.started":"2024-10-04T11:52:35.626209Z","shell.execute_reply":"2024-10-04T11:52:44.569824Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa531167bea64c78a442746c5de4badb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f475fbd925446c7ac0acaaec27d66ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"850c6b79c0674099bde7d69de8d5c323"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_30/2023214181.py:15: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n  llm = HuggingFacePipeline(pipeline=pipe)\n","output_type":"stream"}]},{"cell_type":"code","source":"class GraphState(TypedDict):\n    initial_query: str\n    query_language: str\n    final_query: str\n    Rag_search: str\n    web_reserch= str\n    final_answer: str\n    new_query:str","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:52:44.571966Z","iopub.execute_input":"2024-10-04T11:52:44.572305Z","iopub.status.idle":"2024-10-04T11:52:44.577351Z","shell.execute_reply.started":"2024-10-04T11:52:44.572254Z","shell.execute_reply":"2024-10-04T11:52:44.576414Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import requests\nimport urllib.parse\n\ndef translatation(state):\n    text = state[\"initial_query\"]\n    base_url = \"https://api.mymemory.translated.net/get\"\n    params = {\n        \"q\": text,\n        \"langpair\": \"ar|en\"\n    }\n    \n    url = f\"{base_url}?{urllib.parse.urlencode(params)}\"\n    \n    response = requests.get(url)\n    \n    if response.status_code == 200:\n        data = response.json()\n        if data[\"responseStatus\"] == 200:\n            state[\"final_query\"] = data[\"responseData\"][\"translatedText\"]\n        else:\n            state[\"final_query\"] = f\"Translation error: {data['responseStatus']}\"\n    else:\n        state[\"final_query\"] = f\"HTTP error: {response.status_code}\"\n           \n    return state","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:52:44.590954Z","iopub.execute_input":"2024-10-04T11:52:44.591245Z","iopub.status.idle":"2024-10-04T11:52:44.604248Z","shell.execute_reply.started":"2024-10-04T11:52:44.591213Z","shell.execute_reply":"2024-10-04T11:52:44.603388Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Example usage\nstate = {\"initial_query\": \"مرحبا، كيف حالك؟\"}\nresult = translatation(state)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:52:44.605393Z","iopub.execute_input":"2024-10-04T11:52:44.605705Z","iopub.status.idle":"2024-10-04T11:52:44.908466Z","shell.execute_reply.started":"2024-10-04T11:52:44.605666Z","shell.execute_reply":"2024-10-04T11:52:44.907664Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def language_detection_chain(state):\n    prompt = PromptTemplate(\n        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a Language Detection Agent. Your task is to determine if the given text is in English or not.\n\n<|eot_id|><|start_header_id|>user<|end_header_id|> Analyze the following text and \ndetermine if it's in English or not. If it's in English, respond with the string \"english\". \nIf it's not in English (i.e., it's in any other language), respond with the string \"another\".\n\nOnly respond with either \"english\" or \"another\", nothing else.\n\nText to analyze: {initial_query}\n\n<|eot_id|> <|start_header_id|>assistant<|end_header_id|> \"\"\",\n        input_variables=[\"initial_query\"],\n    )\n\n    return prompt | llm | StrOutputParser()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:52:44.909618Z","iopub.execute_input":"2024-10-04T11:52:44.909931Z","iopub.status.idle":"2024-10-04T11:52:44.915356Z","shell.execute_reply.started":"2024-10-04T11:52:44.909897Z","shell.execute_reply":"2024-10-04T11:52:44.914345Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def route_to_rewrite(state):\n    initial_query = state['initial_query']\n    \n    language_detector = language_detection_chain(state)\n    query_language = language_detector.invoke({\"initial_query\": initial_query})\n    print(f\"Detected language: {query_language}\")\n    \n\n    state[\"query_language\"] = query_language\n\n    if \"english\" in query_language.lower():\n        state[\"final_query\"] = state[\"initial_query\"]\n        print(\"english language\")\n        return \"english\"\n    else:\n        state[\"query_language\"]='another'\n        print(\"another language\")\n        return \"another\"","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:52:44.919254Z","iopub.execute_input":"2024-10-04T11:52:44.919586Z","iopub.status.idle":"2024-10-04T11:52:44.930794Z","shell.execute_reply.started":"2024-10-04T11:52:44.919552Z","shell.execute_reply":"2024-10-04T11:52:44.930024Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"state = GraphState(\n     initial_query=\"what is pretraining (language modeling) and post-training\",\n     query_language=\"\",\n     final_query=\"\",\n     new_query=\"\", \n     Rag_search = \"\" ,\n     web_research= \"\",\n     web_search_answer=\"\"\n\n )\n \nroute_to_rewrite(state)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:52:44.931877Z","iopub.execute_input":"2024-10-04T11:52:44.932192Z","iopub.status.idle":"2024-10-04T11:52:47.244004Z","shell.execute_reply.started":"2024-10-04T11:52:44.932158Z","shell.execute_reply":"2024-10-04T11:52:47.243120Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"},{"name":"stdout","text":"Detected language:  english\nenglish language\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'english'"},"metadata":{}}]},{"cell_type":"code","source":"\ntemplate = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\nYou are an advanced Search Query Improvement Agent. Your task is to refine and enhance a given input question to create a more effective search query.\n\nGuidelines:\n1. Analyze the input question carefully.\n2. Identify key concepts and important context.\n3. Add relevant keywords or phrases to improve specificity.\n4. Remove unnecessary words or ambiguous terms.\n5. Ensure the improved query is clear, concise, and focused.\n6. Maintain the original intent of the question.\n\nRemember: Respond ONLY with the single improved search query. Do not include any explanations .\n<|eot_id|>\n\n<|start_header_id|>user<|end_header_id|>\nGenerate a single comprehensive improved search query based on this input question:\n{question}\n<|eot_id|>\n\n<|start_header_id|>assistant<|end_header_id|>\n\"\"\"\n\nprompt_rag_fusion = ChatPromptTemplate.from_template(template)\n\n\ngenerate_queries = (\n    prompt_rag_fusion \n    | llm\n    | StrOutputParser() \n)\n\n## Chain for extracting relevant documents\n\nretrieval_chain_rag = generate_queries \n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:52:47.245134Z","iopub.execute_input":"2024-10-04T11:52:47.245447Z","iopub.status.idle":"2024-10-04T11:52:47.251760Z","shell.execute_reply.started":"2024-10-04T11:52:47.245407Z","shell.execute_reply":"2024-10-04T11:52:47.250776Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def query_translation(state):\n    initial_query=state[\"initial_query\"]\n    language_detector = language_detection_chain(state)\n    query_language = language_detector.invoke({\"initial_query\": initial_query})\n    if \"english\" in query_language.lower():\n        state[\"final_query\"]=state[\"initial_query\"]\n    question =state[\"final_query\"]\n    results = retrieval_chain_rag.invoke({\"question\": question})\n    state['new_query']=results\n    return state\n# Example usage\nstate = GraphState(\n     initial_query=\"what is pretraining (language modeling) and post-training \",\n     query_language=\"\",\n     final_query=\"what is pretraining (language modeling) and post-training\",\n     new_query=\"\",\n     Rag_search=\"\",\n     context=\"\",\n     final_answer=\"\"\n )\nquery_translation(state)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:52:47.253020Z","iopub.execute_input":"2024-10-04T11:52:47.253413Z","iopub.status.idle":"2024-10-04T11:53:00.276315Z","shell.execute_reply.started":"2024-10-04T11:52:47.253370Z","shell.execute_reply":"2024-10-04T11:53:00.275377Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'initial_query': 'what is pretraining (language modeling) and post-training ',\n 'query_language': '',\n 'final_query': 'what is pretraining (language modeling) and post-training ',\n 'new_query': '\"Pretraining language models and post-training techniques: a comprehensive overview\"',\n 'Rag_search': '',\n 'context': '',\n 'final_answer': ''}"},"metadata":{}}]},{"cell_type":"code","source":"def query_translation(state):\n    initial_query=state[\"initial_query\"]\n    language_detector = language_detection_chain(state)\n    query_language = language_detector.invoke({\"initial_query\": initial_query})\n    if \"english\" in query_language.lower():\n        state[\"final_query\"]=state[\"initial_query\"]\n    question =state[\"final_query\"]\n    results = retrieval_chain_rag.invoke({\"question\": question})\n    state['new_query']=results\n    return state\n\n# Example usage\nstate = GraphState(\n     initial_query=\"what is agi \",\n     query_language=\"\",\n     final_query=\"what is agi\",\n     new_query=\"\",\n     Rag_search=\"\",\n     context=\"\",\n     final_answer=\"\"\n )\nquery_translation(state)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:53:00.277627Z","iopub.execute_input":"2024-10-04T11:53:00.278031Z","iopub.status.idle":"2024-10-04T11:53:08.282269Z","shell.execute_reply.started":"2024-10-04T11:53:00.277986Z","shell.execute_reply":"2024-10-04T11:53:08.281384Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'initial_query': 'what is agi ',\n 'query_language': '',\n 'final_query': 'what is agi ',\n 'new_query': '\"Artificial General Intelligence definition\"',\n 'Rag_search': '',\n 'context': '',\n 'final_answer': ''}"},"metadata":{}}]},{"cell_type":"code","source":"def research_into_retrieval(state):\n    print(\"--- SEARCH INFO RAG RETRIEVAL---\")\n    new_query = state[\"new_query\"]\n \n\n    print(f\"Searching for: {new_query}\")\n    docs = pinecone_vector_store.similarity_search(new_query, k=3)\n    combined_content = \"\\n\".join([doc.page_content for doc in docs])\n    Rag_search = str(combined_content)\n    state[\"Rag_search\"]=Rag_search\n    \n\n    return state","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:53:08.283505Z","iopub.execute_input":"2024-10-04T11:53:08.283881Z","iopub.status.idle":"2024-10-04T11:53:08.289618Z","shell.execute_reply.started":"2024-10-04T11:53:08.283846Z","shell.execute_reply":"2024-10-04T11:53:08.288563Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"state = research_into_retrieval(state)\nprint(state)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:53:08.291024Z","iopub.execute_input":"2024-10-04T11:53:08.291459Z","iopub.status.idle":"2024-10-04T11:53:08.751680Z","shell.execute_reply.started":"2024-10-04T11:53:08.291396Z","shell.execute_reply":"2024-10-04T11:53:08.750708Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"--- SEARCH INFO RAG RETRIEVAL---\nSearching for: \"Artificial General Intelligence definition\"\n{'initial_query': 'what is agi ', 'query_language': '', 'final_query': 'what is agi ', 'new_query': '\"Artificial General Intelligence definition\"', 'Rag_search': \"this is the answer that you would want from some of these models. So this is an example. I can't read very well on my computer, but my kid needs to do a science, no, let's read this one. Can you write a short introduction about the relevance of the term monopsony, and then it says monopsony refers to a market structure blah, blah, blah, and that's a human number with that. So actually this is open assistant, which was a way to collect data online by humans. So this type of supervised fine-tuning whileignment is really the key of chat GPT. This is what made the big jump from GPT3, which was mostly something that was known by AI researchers to chat GPT, which became known by basically everyone. So the problem with human data is that it's very slow to collect and very expensive. So one possible simple idea is to use LMS to scale data collection. So that's exactly what we did with alpaca one year ago. What we did is we asked humans, or we use a dataset of human question answers. So there\\nthings are usually more like tech driven or like tech savvy. So a lot of the questions that you will ask are more like tech stuff, discussing software errors, inquiries about AI tools and all these things. So another issue is cost and speed. If you really want to use something like this for development process, it will be too costly because you will need to basically pay a lot of humans to do that. So one simple idea is again as we said many times just use our limit set of humans. You probably know the drill at this point, steps for every instruction generate outputs by some baseline and the model that you want to evaluate. So he imagined that I am comparing an answer from chat GPT and from mistral. I'm just asking a model, another model which one is better and I just basically average that out. Yeah, I asked GPT for which one is better. I average that out of my entire distribution over my entire benchmark or data set and that gives me a win rate, so win probability for one model\\nerrors, inquiries about AI tools, and all these things. So another issue is cost and speed. If you really want to use something like this for development process, it will be too costly because you will need to basically pay a lot of humans to do that. So one simple idea is, again, as we said many times, just use our limit set of humans. You probably know the drill at this point. Steps for every instruction generate outputs by some baseline, and the model that you want to evaluate. So he imagined that I am comparing an answer from chatgpt and from mistral. I'm just asking another model, which one is better, and I just basically averaged that out. Yeah, I asked you, GPT4 which one is better. I averaged that out of my entire distribution over my entire benchmark or data set, and that gives me a win rate, so win probability for one model compared to another one, and now you can rank models. And this is the Alpeque Ival leaderboard. So the benefits of this is that actually we show we get\", 'context': '', 'final_answer': ''}\n","output_type":"stream"}]},{"cell_type":"code","source":"web_retriever = TavilySearchAPIRetriever(k=1)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:53:08.752817Z","iopub.execute_input":"2024-10-04T11:53:08.753152Z","iopub.status.idle":"2024-10-04T11:53:08.757234Z","shell.execute_reply.started":"2024-10-04T11:53:08.753113Z","shell.execute_reply":"2024-10-04T11:53:08.756365Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def concatenate_strings(state):\n    print(\"--- SEARCH INFO WEB---\")\n    web_context =web_retriever.invoke(state[\"new_query\"])\n    web_context = str(web_context)\n    concatenated = \"this is information from document \" +state[\"Rag_search\"] + \" \" +\"this is information from web \"+ web_context\n    \n    state[\"context\"] = concatenated\n    \n    return state\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:53:08.758777Z","iopub.execute_input":"2024-10-04T11:53:08.759161Z","iopub.status.idle":"2024-10-04T11:53:08.768495Z","shell.execute_reply.started":"2024-10-04T11:53:08.759116Z","shell.execute_reply":"2024-10-04T11:53:08.767681Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def web_Retrieval_chain(state):\n    prompt = PromptTemplate(\n        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n        Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n        Use three sentences maximum and keep the answer concise <|eot_id|><|start_header_id|>user<|end_header_id|>\n        Question: {question} \n        Context: {context} \n        Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n    )\n\n    concatenate_strings(state)\n\n    chain = (\n    {\"context\": lambda x: state['context'] , \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n    )\n    state[\"final_answer\"]=chain.invoke(state[\"new_query\"])\n    print(\"--- THE final answer--\")\n    print(state[\"final_answer\"])\n    return state","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:53:08.769486Z","iopub.execute_input":"2024-10-04T11:53:08.769760Z","iopub.status.idle":"2024-10-04T11:53:08.780064Z","shell.execute_reply.started":"2024-10-04T11:53:08.769729Z","shell.execute_reply":"2024-10-04T11:53:08.779284Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"x = web_Retrieval_chain(state)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:53:08.781115Z","iopub.execute_input":"2024-10-04T11:53:08.781399Z","iopub.status.idle":"2024-10-04T11:54:12.985043Z","shell.execute_reply.started":"2024-10-04T11:53:08.781368Z","shell.execute_reply":"2024-10-04T11:54:12.984074Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"--- SEARCH INFO WEB---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"--- THE final answer--\n\n\nArtificial General Intelligence (AGI) refers to a theoretical type of artificial intelligence capable of performing cognitive tasks at a skill level equal to or greater than that of a human. It is a highly advanced form of AI that can understand, learn, and apply knowledge across a wide range of tasks, similar to human intelligence. AGI is still a topic of ongoing research and development in the field of artificial intelligence.\n","output_type":"stream"}]},{"cell_type":"code","source":"workflow = StateGraph(GraphState)\n\n# Define the nodes\nworkflow.add_node(\"translatation\", translatation)\nworkflow.add_node(\"query_translation\", query_translation)\n\nworkflow.add_node(\"research_info_retrieval\", research_into_retrieval)\n\nworkflow.add_node(\"web_Retrieval_chain\", web_Retrieval_chain)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:54:12.986266Z","iopub.execute_input":"2024-10-04T11:54:12.986556Z","iopub.status.idle":"2024-10-04T11:54:12.994125Z","shell.execute_reply.started":"2024-10-04T11:54:12.986525Z","shell.execute_reply":"2024-10-04T11:54:12.993132Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"<langgraph.graph.state.StateGraph at 0x7c4072f86d40>"},"metadata":{}}]},{"cell_type":"code","source":"workflow.add_conditional_edges(START,\n                               route_to_rewrite,\n                               {\"english\": \"query_translation\",\"another\": \"translatation\",})\nworkflow.add_edge(\"query_translation\" , \"research_info_retrieval\")\nworkflow.add_edge(\"translatation\" , \"query_translation\")\n\nworkflow.add_edge(\"research_info_retrieval\" , \"web_Retrieval_chain\")\n\n\nworkflow.add_edge(\"web_Retrieval_chain\" , END)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:54:12.995341Z","iopub.execute_input":"2024-10-04T11:54:12.995734Z","iopub.status.idle":"2024-10-04T11:54:13.006701Z","shell.execute_reply.started":"2024-10-04T11:54:12.995687Z","shell.execute_reply":"2024-10-04T11:54:13.005834Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"<langgraph.graph.state.StateGraph at 0x7c4072f86d40>"},"metadata":{}}]},{"cell_type":"code","source":"app = workflow.compile()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:54:13.007919Z","iopub.execute_input":"2024-10-04T11:54:13.008520Z","iopub.status.idle":"2024-10-04T11:54:13.018509Z","shell.execute_reply.started":"2024-10-04T11:54:13.008475Z","shell.execute_reply":"2024-10-04T11:54:13.017524Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"display(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:54:13.019727Z","iopub.execute_input":"2024-10-04T11:54:13.020423Z","iopub.status.idle":"2024-10-04T11:54:13.610018Z","shell.execute_reply.started":"2024-10-04T11:54:13.020373Z","shell.execute_reply":"2024-10-04T11:54:13.609071Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"image/jpeg":"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","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}]},{"cell_type":"code","source":"inputs = {\"initial_query\":\"ما هو الذكاء التوليدي \"}\nfor output in app.stream(inputs):\n    for key, value in output.items():\n        print(f\"Finished running:\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:54:13.611679Z","iopub.execute_input":"2024-10-04T11:54:13.611987Z","iopub.status.idle":"2024-10-04T11:55:34.511197Z","shell.execute_reply.started":"2024-10-04T11:54:13.611955Z","shell.execute_reply":"2024-10-04T11:55:34.510250Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Detected language:  another\nanother language\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Finished running:\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Finished running:\n--- SEARCH INFO RAG RETRIEVAL---\nSearching for: \"Generative Intelligence definition AI capabilities\"\nFinished running:\n--- SEARCH INFO WEB---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"--- THE final answer--\n\n\nGenerative Intelligence, also known as Generative AI, refers to a system of algorithms or computer processes that can create novel output in text, images, or other media based on patterns and structures learned from a dataset. This type of AI is used for tasks such as language generation, image synthesis, and music composition. It has the capability to produce new, original content that is often indistinguishable from human-created work.\nFinished running:\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = {\"initial_query\":\"what is pretraining (language modeling) and post-training \"}\nfor output in app.stream(inputs):\n    for key, value in output.items():\n        print(f\"Finished running:\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:55:34.512569Z","iopub.execute_input":"2024-10-04T11:55:34.512995Z","iopub.status.idle":"2024-10-04T11:56:03.745164Z","shell.execute_reply.started":"2024-10-04T11:55:34.512947Z","shell.execute_reply":"2024-10-04T11:56:03.744253Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Detected language:  english\nenglish language\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Finished running:\n--- SEARCH INFO RAG RETRIEVAL---\nSearching for: \"Pretraining language models and post-training techniques: a comprehensive overview\"\nFinished running:\n--- SEARCH INFO WEB---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"--- THE final answer--\n\n\nI don't know.\nFinished running:\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install gradio","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:56:03.746368Z","iopub.execute_input":"2024-10-04T11:56:03.746719Z","iopub.status.idle":"2024-10-04T11:56:20.134053Z","shell.execute_reply.started":"2024-10-04T11:56:03.746683Z","shell.execute_reply":"2024-10-04T11:56:20.132920Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.4.0)\nRequirement already satisfied: fastapi<1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.111.0)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting gradio-client==1.3.0 (from gradio)\n  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\nRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.0)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.4.0)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.4)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.5)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.5)\nRequirement already satisfied: numpy<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.10.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (24.1)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.2)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.3.0)\nRequirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.9.2)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.0.9)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0.2)\nCollecting ruff>=0.2.2 (from gradio)\n  Downloading ruff-0.6.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting tomlkit==0.12.0 (from gradio)\n  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.3)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.12.2)\nCollecting urllib3~=2.0 (from gradio)\n  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.30.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\nRequirement already satisfied: websockets<13.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.3.0->gradio) (12.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\nRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi<1.0->gradio) (0.37.2)\nRequirement already satisfied: fastapi-cli>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from fastapi<1.0->gradio) (0.0.4)\nRequirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from fastapi<1.0->gradio) (5.10.0)\nRequirement already satisfied: email_validator>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from fastapi<1.0->gradio) (2.1.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.15.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.23.4)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\nRequirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi<1.0->gradio) (2.6.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0->gradio) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0->gradio) (1.0.1)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0->gradio) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0->gradio) (0.22.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\nDownloading ruff-0.6.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\nInstalling collected packages: urllib3, tomlkit, semantic-version, ruff, ffmpy, gradio-client, gradio\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: tomlkit\n    Found existing installation: tomlkit 0.13.2\n    Uninstalling tomlkit-0.13.2:\n      Successfully uninstalled tomlkit-0.13.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.3 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ffmpy-0.4.0 gradio-4.44.1 gradio-client-1.3.0 ruff-0.6.8 semantic-version-2.10.0 tomlkit-0.12.0 urllib3-2.2.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import gradio as gr\n\nclass SAIAYN_APP:\n    def __init__(self, app):\n        self.title = \"Text Generation Gradio App\"\n        self.description = \"This app generates text based on input prompts.\"\n        self.app = app\n\n    \n    def process_input(self, user_input):\n        # Here you can add any processing logic you want\n        inputs = {\"initial_query\": user_input}\n        result = []\n        for output in self.app.stream(inputs):\n            for key, value in output.items():\n                result.append(value)\n        return result[0]\n\n    def launch_app(self):\n        # Define the Gradio interface\n        interface = gr.Interface(\n            fn=self.process_input,  # The function to process the input\n            inputs=gr.components.Textbox(label=\"Input Text\"),  # Input component\n            outputs=gr.components.Textbox(label=\"Output Text\"),  # Output component\n            title=self.title,\n            description=self.description\n        )\n        \n        # Launch the app\n        interface.launch()\n\nif __name__ == \"__main__\":\n    project = SAIAYN_APP(app)\n    project.launch_app()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:56:20.139161Z","iopub.execute_input":"2024-10-04T11:56:20.139481Z","iopub.status.idle":"2024-10-04T11:56:27.762116Z","shell.execute_reply.started":"2024-10-04T11:56:20.139449Z","shell.execute_reply":"2024-10-04T11:56:27.761319Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7860\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\nRunning on public URL: https://721bc5d10eb3da4980.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://721bc5d10eb3da4980.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}